{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae2730-a866-4c63-af2f-1e65c55aa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf42d12-b72f-46d0-a767-ca0d46bdc6e6",
   "metadata": {},
   "source": [
    "## Pull in the news articles and topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8258e3d0-6670-4f85-b948-394202e3dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sgm_to_dataframe(file_path: str) -> pd.DataFrame:\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        sgm_data = file.read()\n",
    "\n",
    "    # Parse the SGML data\n",
    "    soup = BeautifulSoup(sgm_data, 'html.parser')\n",
    "\n",
    "    # List to hold parsed data\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each Reuters tag in the SGML\n",
    "    for reuters in soup.find_all('reuters'):\n",
    "        # Extract the NEWID attribute to serve as an ID\n",
    "        article_id = reuters.get('newid')\n",
    "\n",
    "        # Extract the BODY content\n",
    "        body = reuters.find('body')\n",
    "        body_text = body.get_text().strip() if body else ''\n",
    "\n",
    "        # Extract the TOPICS\n",
    "        topics = reuters.find('topics')\n",
    "        if topics:\n",
    "            # Get all topics listed under <D> tags\n",
    "            topics_list = [d.get_text().strip() for d in topics.find_all('d')]\n",
    "            # If there are topics, add a row for each topic\n",
    "            if topics_list:\n",
    "                for topic in topics_list:\n",
    "                    data.append({'ID': article_id, 'Topic': topic, 'Body': body_text})\n",
    "            else:\n",
    "                # If <topics> tag exists but is empty, add a row with empty string for Topic\n",
    "                data.append({'ID': article_id, 'Topic': '', 'Body': body_text})\n",
    "        else:\n",
    "            # If there's no <topics> tag, add a row with None for Topic\n",
    "            data.append({'ID': article_id, 'Topic': None, 'Body': body_text})\n",
    "\n",
    "    # Create a DataFrame from the parsed data\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47571b4d-ad6e-4fb3-9df7-e1ba3e6e193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_sgm_to_dataframe('data/reuters21578/reut2-000.sgm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02ca47-605e-4ba9-adeb-9c206451dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13147df-ab04-4004-84e2-834b20d7ef23",
   "metadata": {},
   "source": [
    "## Get a list of all possible topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33f8d4-f2b3-45f7-966f-aefa1390d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_topics_in_file(topic_list, file_path):\n",
    "    # Read topics from the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_topics = set(file.read().splitlines())\n",
    "    \n",
    "    # Check if all topics in topic_list are in file_topics\n",
    "    missing_topics = set(topic_list) - file_topics\n",
    "    \n",
    "    if not missing_topics:\n",
    "        return True, []\n",
    "    else:\n",
    "        return False, list(missing_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb9b2e-a877-43f9-a2d4-e8b87246d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = df['Topic'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd95790-5e3a-4bd4-afab-ca12e018a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_topics_in_file(topic_list, 'data/reuters21578/all-topics-strings.lc.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de0461-5ebb-4718-8a5d-9971005c9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_file = 'data/reuters21578/all-topics-strings.lc.txt'\n",
    "with open(topic_file, 'r') as file:\n",
    "    file_topics = set(file.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611bb8d-bf98-4120-ad5b-c934eafe2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list(file_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17340319-83e1-46b9-b7cd-bb15c508febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [s.strip() for s in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6397ad-5e9c-4b0a-9a5c-b138132d0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ffedae-4e45-4e7a-b61d-e28e36f066b9",
   "metadata": {},
   "source": [
    "## Sample from the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47468d2-01a1-4d99-a0cf-9013e0613ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def sample_article_with_n_topics(df: pd.DataFrame, n: int) -> dict:\n",
    "    # Group the DataFrame by ID and aggregate topics into a list\n",
    "    grouped = df.groupby('ID').agg({\n",
    "        'Topic': lambda x: [t for t in x if pd.notna(t) and t != ''],\n",
    "        'Body': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    if n == 0:\n",
    "        # For n = 0, find articles with no topics or empty string topics\n",
    "        articles_with_n_topics = grouped[grouped['Topic'].apply(len) == 0]\n",
    "    else:\n",
    "        # For n > 0, find articles with exactly n topics\n",
    "        articles_with_n_topics = grouped[grouped['Topic'].apply(len) == n]\n",
    "    \n",
    "    # If no articles found with the specified number of topics, return None\n",
    "    if articles_with_n_topics.empty:\n",
    "        return None\n",
    "    \n",
    "    # Randomly select one article\n",
    "    selected_article = articles_with_n_topics.sample(n=1).iloc[0]\n",
    "    \n",
    "    # Create the result dictionary\n",
    "    result = {\n",
    "        'ID': selected_article['ID'],\n",
    "        'Topics': ', '.join(selected_article['Topic']) if n > 0 else '',\n",
    "        'Body': selected_article['Body']\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16929f8a-b6fd-4c6c-8370-28c110379b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_article_with_n_topics(df, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1053d7b-d9bc-4060-988d-9a8bb028a7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "267edf11-b051-4b2a-8e68-2735cbc0fbb0",
   "metadata": {},
   "source": [
    "## Prompt ideas\n",
    "\n",
    "I would like you to create a Python program that will take in the text from a news article and identify any topics from a pre-defined list of possible topics. \n",
    "\n",
    "Here are the list of possible topics: {all_topics}\n",
    "\n",
    "Here are a few examples:\n",
    "\n",
    "Example 1:\n",
    "Article: {article_1}\n",
    "Topics: {topics_1}\n",
    "\n",
    "Example 2:\n",
    "Article: {article_2}\n",
    "Topics: {topics_2}\n",
    "\n",
    "Example 3:\n",
    "Article: {article_3}\n",
    "Topics: {topics_3}\n",
    "\n",
    "The input of the program will be the text and the output/return should be a list of any topics that should be included in the article.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Create a Python program that takes the text of a news article as input and identifies relevant topics from a pre-defined list. The program should be efficient and able to process multiple articles quickly.\n",
    "\n",
    "List of possible topics: {all_topics}\n",
    "\n",
    "The program should:\n",
    "1. Preprocess the input text (e.g., remove special characters, convert to lowercase)\n",
    "2. Identify topics that are explicitly mentioned or strongly implied in the article\n",
    "3. Handle partial matches and consider the context of words\n",
    "4. Return a list of identified topics\n",
    "5. Return an empty list if no topics are identified\n",
    "6. Handle potential errors gracefully\n",
    "\n",
    "Examples:\n",
    "\n",
    "Example 1 (Multiple topics):\n",
    "Article: {article_1}\n",
    "Topics: {topics_1}\n",
    "\n",
    "Example 2 (Single topic):\n",
    "Article: {article_2}\n",
    "Topics: {topics_2}\n",
    "\n",
    "Example 3 (No topics):\n",
    "Article: {article_3}\n",
    "Topics: []\n",
    "\n",
    "Example 4 (Long article, truncated for brevity):\n",
    "Article: {article_4}\n",
    "Topics: {topics_4}\n",
    "\n",
    "Input: The full text of a news article as a string\n",
    "Output: A list of strings representing the identified topics\n",
    "\n",
    "Please provide the Python code for this program, including any necessary functions for preprocessing, topic identification, and main execution. Also, include brief comments explaining the logic of your approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbbd63-aba0-4729-955f-ff370555f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'topics: {topics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d46d5-b17b-4c75-899c-6d6b05e13653",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = sample_article_with_n_topics(df, n=0)\n",
    "single_topic = sample_article_with_n_topics(df, n=1)\n",
    "random_number = random.randint(2, 4)\n",
    "multiple_topics = sample_article_with_n_topics(df, n=random_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99036a-1d77-49f6-aefb-e8fb1027ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3671c40-5e38-45be-85d4-8b3fe2d0f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d75d0-47d6-4158-96dc-bad34ca9c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f7977-ed02-4549-9254-44e965cedc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(all_topics, no_topics, single_topic, multiple_topics):\n",
    "    result = f\"\"\"\n",
    "    Create a Python program that takes the text of a news article as input and identifies relevant topics from a pre-defined list. The program should be efficient and able to process multiple articles quickly.\n",
    "\n",
    "List of possible topics: {all_topics}\n",
    "\n",
    "The program should:\n",
    "1. Preprocess the input text (e.g., remove special characters, convert to lowercase)\n",
    "2. Identify topics that are explicitly mentioned or strongly implied in the article\n",
    "3. Handle partial matches and consider the context of words\n",
    "4. Return a list of identified topics\n",
    "5. Return an empty list if no topics are identified\n",
    "6. Handle potential errors gracefully\n",
    "\n",
    "Examples:\n",
    "\n",
    "Example 1 (Multiple topics):\n",
    "Article: {multiple_topics['Body']}\n",
    "Topics: [{multiple_topics['Topics']}]\n",
    "\n",
    "Example 2 (Single topic):\n",
    "Article: {single_topic['Body']}\n",
    "Topics: [{single_topic['Topics']}]\n",
    "\n",
    "Example 3 (No topics):\n",
    "Article: {no_topics['Body']}\n",
    "Topics: []\n",
    "\n",
    "Input: The full text of a news article as a string\n",
    "Output: A list of strings representing the identified topics\n",
    "\n",
    "Please provide the Python code for this program, including any necessary functions for preprocessing, topic identification, and main execution. Also, include brief comments explaining the logic of your approach.\n",
    "    \"\"\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326ca8d-bf90-4e3d-bb19-6c53148a2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = generate_prompt(all_topics=topics,\n",
    "                no_topics=no_topics, \n",
    "                single_topic=single_topic, \n",
    "                multiple_topics=multiple_topics\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82176639-a3b9-4152-a0ee-41708092463f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe39a42-a995-45b5-be73-2929bd057640",
   "metadata": {},
   "source": [
    "## Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff0208-1706-4502-9c15-37db41c8faba",
   "metadata": {},
   "source": [
    "### Claude\n",
    "\n",
    "prompt:\n",
    "\n",
    "Create a Python program that takes the text of a news article as input and identifies relevant topics from a pre-defined list. The program should be efficient and able to process multiple articles quickly.\n",
    "\n",
    "List of possible topics: ['acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', 'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', 'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', 'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', 'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin', 'meal-feed', 'mexpeso', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', 'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', 'rape-oil', 'rapeseed', 'red-bean', 'reserves', 'retail', 'rice', 'ringgit', 'rubber', 'rupiah', 'rye', 'saudriyal', 'sfr', 'ship', 'silk', 'silver', 'singdlr', 'skr', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil', 'veg-oil', 'wheat', 'wool', 'wpi', 'yen', 'zinc']\n",
    "\n",
    "The program should:\n",
    "1. Preprocess the input text (e.g., remove special characters, convert to lowercase)\n",
    "2. Identify topics that are explicitly mentioned or strongly implied in the article\n",
    "3. Handle partial matches and consider the context of words\n",
    "4. Return a list of identified topics\n",
    "5. Return an empty list if no topics are identified\n",
    "6. Handle potential errors gracefully\n",
    "\n",
    "Examples:\n",
    "\n",
    "Example 1 (Multiple topics):\n",
    "Article: The Commodity Credit Corporation, CCC,\n",
    "has accepted an export bonus offer to cover the sale of 37,000\n",
    "long tons of wheat flour to North Yemen, the U.S. Agriculture\n",
    "Department said.\n",
    "    The wheat four is for shipment March-May and the bonus\n",
    "awarded was 119.05 dlrs per tonnes and will be paid in the form\n",
    "of commodities from the CCC inventory.\n",
    "    The bonus was awarded to the Pillsbury Company.\n",
    "    The wheat flour purchases complete the Export Enhancement\n",
    "Program initiative announced in April, 1986, it said.\n",
    " Reuter\n",
    "\u0003\n",
    "Topics: [wheat, grain]\n",
    "\n",
    "Example 2 (Single topic):\n",
    "Article: Union Carbide Corp is looking to\n",
    "acquisitions and joint ventures to aid its chemicals and\n",
    "plastics growth, according the H.W. Lichtenberger, president of\n",
    "Chemicals and Plastics.\n",
    "    Describing this as a major departure in the company's\n",
    "approach to commercial development, he told the annual new\n",
    "business forum of the Commercial Development Association \"We\n",
    "are looking to acquisitions and joint ventures when they look\n",
    "like the fastest and most promising routes to the growth\n",
    "markets we've identified.\"\n",
    "    Not very long ago Union Carbide had the attitude \"that if\n",
    "we couldn't do it ourselves, it wasn't worth doing. Or, if it\n",
    "was worth doing, we had to go it alone,\" Lichtenberger\n",
    "explained.\n",
    "    He said \"there are times when exploiting a profitable\n",
    "market is done best with a partner. Nor do we see any need to\n",
    "plow resources into a technology we may not have if we can link\n",
    "up profitably with someone who is already there.\"\n",
    "    He said Carbide has extended its catalyst business that way\n",
    "and is now extending its specialty chemicals business in the\n",
    "same way.\n",
    " Reuter\n",
    "\u0003\n",
    "Topics: [acq]\n",
    "\n",
    "Example 3 (No topics):\n",
    "Article: The total value of Indonesia's exports\n",
    "fell in calendar 1986 to 15.995 billion dlrs from 18.762\n",
    "billion in calendar 1985, according to the central bank's\n",
    "latest report.\n",
    "    The value of crude oil exports fell to 7.431 billion dlrs\n",
    "in 1986 from 8.976 billion in 1985, while liquefied natural gas\n",
    "exports dropped to 2.795 billion dlrs from 3.802 billion in\n",
    "1985.\n",
    "    The value of Indonesia's non-oil exports also fell in\n",
    "calendar 1986, to 5.768 billion dlrs from 5.983 billion in\n",
    "1985.\n",
    " REUTER\n",
    "\u0003\n",
    "Topics: []\n",
    "\n",
    "Input: The full text of a news article as a string\n",
    "Output: A list of strings representing the identified topics\n",
    "\n",
    "Please provide the Python code for this program, including any necessary functions for preprocessing, topic identification, and main execution. Also, include brief comments explaining the logic of your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6c2a0-6070-4a7b-a94d-9503197fd2ad",
   "metadata": {},
   "source": [
    "Program 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2335df8-8856-4f82-a50d-7cdc03277434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "# List of predefined topics\n",
    "TOPICS = ['acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', 'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', 'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', 'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', 'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin', 'meal-feed', 'mexpeso', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', 'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', 'rape-oil', 'rapeseed', 'red-bean', 'reserves', 'retail', 'rice', 'ringgit', 'rubber', 'rupiah', 'rye', 'saudriyal', 'sfr', 'ship', 'silk', 'silver', 'singdlr', 'skr', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil', 'veg-oil', 'wheat', 'wool', 'wpi', 'yen', 'zinc']\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess the input text by converting to lowercase and removing special characters.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def identify_topics(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify topics in the preprocessed text.\n",
    "    \"\"\"\n",
    "    identified_topics = set()\n",
    "    words = text.split()\n",
    "    \n",
    "    for topic in TOPICS:\n",
    "        # Check for exact matches\n",
    "        if topic in words:\n",
    "            identified_topics.add(topic)\n",
    "        else:\n",
    "            # Check for partial matches and context\n",
    "            topic_parts = topic.split('-')\n",
    "            if all(part in words for part in topic_parts):\n",
    "                identified_topics.add(topic)\n",
    "    \n",
    "    return list(identified_topics)\n",
    "\n",
    "def process_article(article: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Process a single article and return identified topics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        preprocessed_text = preprocess_text(article)\n",
    "        topics = identify_topics(preprocessed_text)\n",
    "        return topics\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate the usage of the program.\n",
    "    \"\"\"\n",
    "    article = input(\"Enter the news article text: \")\n",
    "    topics = process_article(article)\n",
    "    \n",
    "    if topics:\n",
    "        print(\"Identified topics:\", topics)\n",
    "    else:\n",
    "        print(\"No topics identified.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451c5c5-7dce-4bce-b6f4-4cd6ee607d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = sample_article_with_n_topics(df, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad6a89d-8a3e-4ba0-b32f-63b026b5df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd9459-6c0c-4be0-a2fb-0c6f275a1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_article(article['Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23514962-2e0e-4097-af77-5d43fea1935f",
   "metadata": {},
   "source": [
    "Program 2 (with fuzzy matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3cf47e-df24-4263-a79a-2c40d13b4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# You might need to install the fuzzywuzzy library:\n",
    "# pip install fuzzywuzzy python-Levenshtein\n",
    "\n",
    "# List of predefined topics\n",
    "TOPICS = ['acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', 'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', 'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', 'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', 'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin', 'meal-feed', 'mexpeso', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', 'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', 'rape-oil', 'rapeseed', 'red-bean', 'reserves', 'retail', 'rice', 'ringgit', 'rubber', 'rupiah', 'rye', 'saudriyal', 'sfr', 'ship', 'silk', 'silver', 'singdlr', 'skr', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil', 'veg-oil', 'wheat', 'wool', 'wpi', 'yen', 'zinc']\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess the input text by converting to lowercase and removing special characters.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def fuzzy_match(word: str, topic: str, threshold: int = 80) -> bool:\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching between a word and a topic.\n",
    "    Returns True if the match ratio is above the threshold.\n",
    "    \"\"\"\n",
    "    return fuzz.ratio(word, topic) >= threshold\n",
    "\n",
    "def identify_topics(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify topics in the preprocessed text using fuzzy matching.\n",
    "    \"\"\"\n",
    "    identified_topics = set()\n",
    "    words = text.split()\n",
    "    \n",
    "    for topic in TOPICS:\n",
    "        # Check for exact matches\n",
    "        if topic in words:\n",
    "            identified_topics.add(topic)\n",
    "        else:\n",
    "            # Check for fuzzy matches\n",
    "            topic_parts = topic.split('-')\n",
    "            if all(any(fuzzy_match(word, part) for word in words) for part in topic_parts):\n",
    "                identified_topics.add(topic)\n",
    "    \n",
    "    return list(identified_topics)\n",
    "\n",
    "def process_article(article: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Process a single article and return identified topics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        preprocessed_text = preprocess_text(article)\n",
    "        topics = identify_topics(preprocessed_text)\n",
    "        return topics\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate the usage of the program.\n",
    "    \"\"\"\n",
    "    article = input(\"Enter the news article text: \")\n",
    "    topics = process_article(article)\n",
    "    \n",
    "    if topics:\n",
    "        print(\"Identified topics:\", topics)\n",
    "    else:\n",
    "        print(\"No topics identified.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb2a78-6fe1-41b9-9fc4-2456042ab21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = sample_article_with_n_topics(df, n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dadd97-1ae3-48fb-9c57-4f305c594768",
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ce0f8-9a93-4a10-81f8-b4f81bc9802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_article(article['Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875efd06-9057-4a84-b1e1-4916045f6d5e",
   "metadata": {},
   "source": [
    "## Llama 3.1 70B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85198e61-1a53-4316-81e8-9f0c161da18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess the input text by removing special characters and converting to lowercase.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "    str: The preprocessed text.\n",
    "    \"\"\"\n",
    "    # Remove special characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text).lower()\n",
    "    return text\n",
    "\n",
    "def identify_topics(text: str, topics: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify topics that are explicitly mentioned or strongly implied in the article.\n",
    "\n",
    "    Args:\n",
    "    text (str): The preprocessed text.\n",
    "    topics (List[str]): The list of possible topics.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of identified topics.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store identified topics\n",
    "    identified_topics = []\n",
    "\n",
    "    # Iterate over each topic\n",
    "    for topic in topics:\n",
    "        # Check if the topic is mentioned in the text\n",
    "        if topic in text:\n",
    "            # Add the topic to the list of identified topics\n",
    "            identified_topics.append(topic)\n",
    "\n",
    "    # Return the list of identified topics\n",
    "    return identified_topics\n",
    "\n",
    "def main(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Main function to identify topics in a news article.\n",
    "\n",
    "    Args:\n",
    "    text (str): The full text of a news article.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of strings representing the identified topics.\n",
    "    \"\"\"\n",
    "    # Preprocess the input text\n",
    "    preprocessed_text = preprocess_text(text)\n",
    "\n",
    "    # Define the list of possible topics\n",
    "    topics = ['acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', 'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', 'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', 'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', 'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin','meal-feed','mexpeso','money-fx','money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', 'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', 'rape-oil', 'rapeseed','red-bean','reserves','retail', 'rice', 'ringgit', 'rubber', 'rupiah', 'rye','saudriyal','sfr','ship','silk','silver','singdlr','skr','sorghum','soy-meal','soy-oil','soybean','stg','strategic-metal','sugar','sun-meal','sun-oil','sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil','veg-oil', 'wheat', 'wool', 'wpi', 'yen', 'zinc']\n",
    "\n",
    "    # Identify topics in the preprocessed text\n",
    "    identified_topics = identify_topics(preprocessed_text, topics)\n",
    "\n",
    "    # Return the list of identified topics\n",
    "    return identified_topics\n",
    "\n",
    "# Example usage:\n",
    "text = \"The Commodity Credit Corporation, CCC, has accepted an export bonus offer to cover the sale of 37,000 long tons of wheat flour to North Yemen, the U.S. Agriculture Department said.\"\n",
    "print(main(text))  # Output: ['wheat', 'grain']\n",
    "\n",
    "text = \"Union Carbide Corp is looking to acquisitions and joint ventures to aid its chemicals and plastics growth, according the H.W. Lichtenberger, president of Chemicals and Plastics.\"\n",
    "print(main(text))  # Output: ['acq']\n",
    "\n",
    "text = \"The total value of Indonesia's exports fell in calendar 1986 to 15.995 billion dlrs from 18.762 billion in calendar 1985, according to the central bank's latest report.\"\n",
    "print(main(text))  # Output: []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad17d6-8c99-4bd8-9e1a-914ab5afbc73",
   "metadata": {},
   "source": [
    "## GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d918a-27e5-4ae1-afa5-950f55715c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Pre-defined list of topics\n",
    "TOPICS = [\n",
    "    'acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', \n",
    "    'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', \n",
    "    'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', \n",
    "    'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', \n",
    "    'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', \n",
    "    'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', \n",
    "    'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', \n",
    "    'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', \n",
    "    'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin', 'meal-feed', 'mexpeso', \n",
    "    'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', \n",
    "    'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', \n",
    "    'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', \n",
    "    'rape-oil', 'rapeseed', 'red-bean', 'reserves', 'retail', 'rice', 'ringgit', 'rubber', \n",
    "    'rupiah', 'rye', 'saudriyal', 'sfr', 'ship', 'silk', 'silver', 'singdlr', 'skr', 'sorghum', \n",
    "    'soy-meal', 'soy-oil', 'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', \n",
    "    'sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil', 'veg-oil', 'wheat', 'wool', \n",
    "    'wpi', 'yen', 'zinc'\n",
    "]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess the input text by removing special characters and converting to lowercase.\n",
    "    \"\"\"\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def identify_topics(text, topics):\n",
    "    \"\"\"\n",
    "    Identify topics that are explicitly mentioned or strongly implied in the article.\n",
    "    \"\"\"\n",
    "    identified_topics = []\n",
    "    # Preprocess text\n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    for topic in topics:\n",
    "        # Check for exact matches and contextually related matches\n",
    "        if re.search(r'\\b' + topic.replace('-', r'[-\\s]') + r'\\b', processed_text):\n",
    "            identified_topics.append(topic)\n",
    "    \n",
    "    return identified_topics\n",
    "\n",
    "def main():\n",
    "    # Example articles\n",
    "    articles = [\n",
    "        \"The Commodity Credit Corporation, CCC, has accepted an export bonus offer to cover the sale of 37,000 long tons of wheat flour to North Yemen, the U.S. Agriculture Department said. The wheat four is for shipment March-May and the bonus awarded was 119.05 dlrs per tonnes and will be paid in the form of commodities from the CCC inventory. The bonus was awarded to the Pillsbury Company. The wheat flour purchases complete the Export Enhancement Program initiative announced in April, 1986, it said. Reuter\",\n",
    "        \"Union Carbide Corp is looking to acquisitions and joint ventures to aid its chemicals and plastics growth, according the H.W. Lichtenberger, president of Chemicals and Plastics. Describing this as a major departure in the company's approach to commercial development, he told the annual new business forum of the Commercial Development Association 'We are looking to acquisitions and joint ventures when they look like the fastest and most promising routes to the growth markets we've identified.' Not very long ago Union Carbide had the attitude 'that if we couldn't do it ourselves, it wasn't worth doing. Or, if it was worth doing, we had to go it alone,' Lichtenberger explained. He said 'there are times when exploiting a profitable market is done best with a partner. Nor do we see any need to plow resources into a technology we may not have if we can link up profitably with someone who is already there.' He said Carbide has extended its catalyst business that way and is now extending its specialty chemicals business in the same way. Reuter\",\n",
    "        \"The total value of Indonesia's exports fell in calendar 1986 to 15.995 billion dlrs from 18.762 billion in calendar 1985, according to the central bank's latest report. The value of crude oil exports fell to 7.431 billion dlrs in 1986 from 8.976 billion in 1985, while liquefied natural gas exports dropped to 2.795 billion dlrs from 3.802 billion in 1985. The value of Indonesia's non-oil exports also fell in calendar 1986, to 5.768 billion dlrs from 5.983 billion in 1985. REUTER\"\n",
    "    ]\n",
    "    \n",
    "    # Process each article\n",
    "    for i, article in enumerate(articles):\n",
    "        topics = identify_topics(article, TOPICS)\n",
    "        print(f\"Article {i+1}: Topics: {topics}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c341d546-cf58-4aa7-a804-4ab3c27473ca",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Feed in the function and some examples of mistakes it made and try to get it to improve/update the function and see if it's able to add accuracy or robustness aside from simply pattern matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6063b3f9-0883-491f-8826-032cce2c6dde",
   "metadata": {},
   "source": [
    "## Feedback improvements\n",
    "\n",
    "The idea is to feed in the function along with some examples of mistakes to allow the LLM to make improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c2866-5af0-471b-91b6-43b1b1de881b",
   "metadata": {},
   "source": [
    "### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e04df-78be-43b8-a8ad-8968af13c69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "# List of predefined topics\n",
    "TOPICS = ['acq', 'alum', 'austdlr', 'austral', 'barley', 'bfr', 'bop', 'can', 'carcass', 'castor-meal', 'castor-oil', 'castorseed', 'citruspulp', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'corn-oil', 'cornglutenfeed', 'cotton', 'cotton-meal', 'cotton-oil', 'cottonseed', 'cpi', 'cpu', 'crude', 'cruzado', 'dfl', 'dkr', 'dlr', 'dmk', 'drachma', 'earn', 'escudo', 'f-cattle', 'ffr', 'fishmeal', 'flaxseed', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-meal', 'groundnut-oil', 'heat', 'hk', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'inventories', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-meal', 'lin-oil', 'linseed', 'lit', 'livestock', 'lumber', 'lupin', 'meal-feed', 'mexpeso', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-meal', 'palm-oil', 'palmkernel', 'peseta', 'pet-chem', 'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand', 'rape-meal', 'rape-oil', 'rapeseed', 'red-bean', 'reserves', 'retail', 'rice', 'ringgit', 'rubber', 'rupiah', 'rye', 'saudriyal', 'sfr', 'ship', 'silk', 'silver', 'singdlr', 'skr', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tapioca', 'tea', 'tin', 'trade', 'tung', 'tung-oil', 'veg-oil', 'wheat', 'wool', 'wpi', 'yen', 'zinc']\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess the input text by converting to lowercase and replacing newlines with spaces.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text\n",
    "\n",
    "def identify_topics(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Identify topics in the preprocessed text.\n",
    "    \"\"\"\n",
    "    identified_topics = set()\n",
    "    \n",
    "    for topic in TOPICS:\n",
    "        # Check for exact matches and matches within words\n",
    "        if re.search(r'\\b' + re.escape(topic) + r'\\b', text) or re.search(r'\\b' + re.escape(topic) + r's?\\b', text):\n",
    "            identified_topics.add(topic)\n",
    "        elif '-' in topic:\n",
    "            # Check for compound topics\n",
    "            parts = topic.split('-')\n",
    "            if all(re.search(r'\\b' + re.escape(part) + r'\\b', text) for part in parts):\n",
    "                identified_topics.add(topic)\n",
    "    \n",
    "    return list(identified_topics)\n",
    "\n",
    "def process_article(article: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Process a single article and return identified topics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        preprocessed_text = preprocess_text(article)\n",
    "        topics = identify_topics(preprocessed_text)\n",
    "        return topics\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing article: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba7528-5580-49b5-ad35-d35cd6be9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = sample_article_with_n_topics(df, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a35e0a-5c30-48fb-8649-5eb3a1f9df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f033b1-7706-488e-b7c6-a0208bb26d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_article(article['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096e17e-c818-433a-8388-b253234d9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = sample_article_with_n_topics(df, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec188890-b08b-4c9b-a649-0b9aebbdbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6047a11-b5ce-4bdf-bfea-4b45482ca3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_article(article['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717482a-4c17-474f-8f86-af94c9169eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
